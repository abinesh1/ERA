{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"YBrpq6BoAKaN"},"source":["### Target:\n","    \n","    - Add LR Scheduler ReduceLROnPlateau.\n","\n","### Results:\n","\n","    - Model has 7979 parameters.\n","\n","    - Train Accuracy = 98.85\n","\n","    - Test Accuracy = 99.44\n","\n","### Analysis:\n","\n","    - Target achieved: crossed 99.4% validation accuracy 3 times (epochs 11, 14 and 15)\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"6PlbomWY3RSq"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1686587713517,"user":{"displayName":"Swapnil Gusani","userId":"03078760041423155735"},"user_tz":-330},"id":"94BxVVBP3WwS","outputId":"8f9d50b4-f77b-4520-d8bd-97f791674cd8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device Selected: mps\n"]}],"source":["# Device\n","if torch.cuda.is_available():\n","    device = \"cuda\"\n","elif torch.backends.mps.is_available():\n","    device = \"mps\"\n","else:\n","    device = \"cpu\"\n","print(\"Device Selected:\", device)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"KE-rKhypAKaY"},"outputs":[],"source":["SEED = 1\n","torch.manual_seed(SEED)\n","\n","if device == 'cuda':\n","    torch.cuda.manual_seed(SEED)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"KpshQ2Ug38m2"},"outputs":[],"source":["# Train data transformations\n","train_transforms = transforms.Compose([\n","    transforms.RandomRotation((-7.0, 7.0), fill=(0,)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,)),\n","])\n","\n","# Test data transformations\n","test_transforms = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"JB79ZYW13-AO"},"outputs":[],"source":["train_data = datasets.MNIST('../data', train=True, download=True, transform=train_transforms)\n","test_data = datasets.MNIST('../data', train=False, download=True, transform=test_transforms)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1686587714281,"user":{"displayName":"Swapnil Gusani","userId":"03078760041423155735"},"user_tz":-330},"id":"avCKK1uL4A68","outputId":"43d58969-ad46-450f-a1a0-7c02967a54fd"},"outputs":[],"source":["batch_size = 64\n","\n","kwargs = {'batch_size': batch_size, 'num_workers': 4, 'pin_memory': True}\n","\n","train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(test_data, shuffle=False, **kwargs)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3014,"status":"ok","timestamp":1686587717283,"user":{"displayName":"Swapnil Gusani","userId":"03078760041423155735"},"user_tz":-330},"id":"v664s8Exiw22","outputId":"4c32c86b-063f-43ce-91e9-6b76a8f981f0"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 9, 28, 28]              81\n","           Dropout-2            [-1, 9, 28, 28]               0\n","              ReLU-3            [-1, 9, 28, 28]               0\n","       BatchNorm2d-4            [-1, 9, 28, 28]              18\n","            Conv2d-5           [-1, 10, 28, 28]             810\n","           Dropout-6           [-1, 10, 28, 28]               0\n","              ReLU-7           [-1, 10, 28, 28]               0\n","         MaxPool2d-8           [-1, 10, 14, 14]               0\n","       BatchNorm2d-9           [-1, 10, 14, 14]              20\n","           Conv2d-10           [-1, 16, 14, 14]           1,440\n","          Dropout-11           [-1, 16, 14, 14]               0\n","             ReLU-12           [-1, 16, 14, 14]               0\n","        MaxPool2d-13             [-1, 16, 7, 7]               0\n","      BatchNorm2d-14             [-1, 16, 7, 7]              32\n","           Conv2d-15             [-1, 16, 7, 7]           2,304\n","           Conv2d-16             [-1, 16, 7, 7]           2,304\n","          Dropout-17             [-1, 16, 7, 7]               0\n","             ReLU-18             [-1, 16, 7, 7]               0\n","AdaptiveAvgPool2d-19             [-1, 16, 1, 1]               0\n","      BatchNorm2d-20             [-1, 16, 1, 1]              32\n","           Conv2d-21             [-1, 32, 1, 1]             512\n","          Dropout-22             [-1, 32, 1, 1]               0\n","             ReLU-23             [-1, 32, 1, 1]               0\n","      BatchNorm2d-24             [-1, 32, 1, 1]              64\n","           Conv2d-25             [-1, 10, 1, 1]             330\n","          Flatten-26                   [-1, 10]               0\n","       LogSoftmax-27                   [-1, 10]               0\n","================================================================\n","Total params: 7,947\n","Trainable params: 7,947\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.53\n","Params size (MB): 0.03\n","Estimated Total Size (MB): 0.57\n","----------------------------------------------------------------\n"]}],"source":["from model import Model4 as Net\n","\n","model = Net()\n","model.summary(input_size=(1, 28, 28))"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"b6rX8BOXAKaa"},"outputs":[],"source":["from utils import train, test"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":791279,"status":"ok","timestamp":1686588509181,"user":{"displayName":"Swapnil Gusani","userId":"03078760041423155735"},"user_tz":-330},"id":"Owqiet9M4TV7","outputId":"7f995a0d-2bac-4789-f023-7b495243b343"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/938 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["Train: Batch Loss=2.2902 Batch_id=937 Average Loss=2.3021 Accuracy=12.76: 100%|██████████| 938/938 [00:15<00:00, 59.72it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Test set: Average loss: 2.2622, Accuracy: 1030/10000 (10.30%)\n","\n","Epoch 2\n"]},{"name":"stderr","output_type":"stream","text":["Train: Batch Loss=2.3023 Batch_id=937 Average Loss=2.2839 Accuracy=13.64: 100%|██████████| 938/938 [00:13<00:00, 69.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Test set: Average loss: 2.2880, Accuracy: 1184/10000 (11.84%)\n","\n","Epoch 00002: reducing learning rate of group 0 to 5.0000e-03.\n","Epoch 3\n"]},{"name":"stderr","output_type":"stream","text":["Train: Batch Loss=2.3184 Batch_id=937 Average Loss=2.2784 Accuracy=13.94: 100%|██████████| 938/938 [00:13<00:00, 70.24it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Test set: Average loss: 2.2374, Accuracy: 1767/10000 (17.67%)\n","\n","Epoch 4\n"]},{"name":"stderr","output_type":"stream","text":["Train: Batch Loss=2.2013 Batch_id=937 Average Loss=2.2758 Accuracy=14.02: 100%|██████████| 938/938 [00:13<00:00, 70.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Test set: Average loss: 2.2524, Accuracy: 1255/10000 (12.55%)\n","\n","Epoch 00004: reducing learning rate of group 0 to 2.5000e-03.\n","Epoch 5\n"]},{"name":"stderr","output_type":"stream","text":["Train: Batch Loss=2.3600 Batch_id=937 Average Loss=2.2723 Accuracy=14.18: 100%|██████████| 938/938 [00:13<00:00, 70.82it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Test set: Average loss: 2.2708, Accuracy: 1245/10000 (12.45%)\n","\n","Epoch 00005: reducing learning rate of group 0 to 1.2500e-03.\n","Epoch 6\n"]},{"name":"stderr","output_type":"stream","text":["Train: Batch Loss=2.2679 Batch_id=937 Average Loss=2.2695 Accuracy=14.52: 100%|██████████| 938/938 [00:13<00:00, 70.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Test set: Average loss: 2.2685, Accuracy: 955/10000 (9.55%)\n","\n","Epoch 00006: reducing learning rate of group 0 to 6.2500e-04.\n","Epoch 7\n"]},{"name":"stderr","output_type":"stream","text":["Train: Batch Loss=2.2317 Batch_id=937 Average Loss=2.2700 Accuracy=14.24: 100%|██████████| 938/938 [00:13<00:00, 70.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Test set: Average loss: 2.2739, Accuracy: 1035/10000 (10.35%)\n","\n","Epoch 00007: reducing learning rate of group 0 to 3.1250e-04.\n","Epoch 8\n"]},{"name":"stderr","output_type":"stream","text":["Train: Batch Loss=2.2895 Batch_id=937 Average Loss=2.2689 Accuracy=14.55: 100%|██████████| 938/938 [00:13<00:00, 69.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Test set: Average loss: 2.2749, Accuracy: 740/10000 (7.40%)\n","\n","Epoch 00008: reducing learning rate of group 0 to 1.5625e-04.\n","Epoch 9\n"]},{"name":"stderr","output_type":"stream","text":["Train: Batch Loss=2.3384 Batch_id=405 Average Loss=2.2704 Accuracy=14.49:  43%|████▎     | 406/938 [00:06<00:09, 58.67it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, num_epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m      9\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m   train(model, device, train_loader, optimizer, criterion)\n\u001b[1;32m     11\u001b[0m   test_loss \u001b[39m=\u001b[39m test(model, device, test_loader, criterion)\n\u001b[1;32m     12\u001b[0m   scheduler\u001b[39m.\u001b[39mstep(test_loss)\n","File \u001b[0;32m~/Documents/ERA/S7/utils.py:47\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     44\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     46\u001b[0m \u001b[39m# Predict\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m pred \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     49\u001b[0m \u001b[39m# Calculate loss\u001b[39;00m\n\u001b[1;32m     50\u001b[0m loss \u001b[39m=\u001b[39m criterion(pred, target)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/Documents/ERA/S7/model.py:196\u001b[0m, in \u001b[0;36mModel4.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 196\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m    197\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransition1(x)\n\u001b[1;32m    198\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=0, verbose=True, factor=0.5)\n","\n","criterion = F.nll_loss\n","num_epochs = 15\n","\n","for epoch in range(1, num_epochs+1):\n","  print(f'Epoch {epoch}')\n","  train(model, device, train_loader, optimizer, criterion)\n","  test_loss = test(model, device, test_loader, criterion)\n","  scheduler.step(test_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":853},"executionInfo":{"elapsed":1556,"status":"ok","timestamp":1686588510699,"user":{"displayName":"Swapnil Gusani","userId":"03078760041423155735"},"user_tz":-330},"id":"Wu0l7dli4eC9","outputId":"209c273d-d6c8-4766-d8df-25758a02ba7d"},"outputs":[],"source":["from utils import plot_stats\n","plot_stats()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":463},"executionInfo":{"elapsed":2783,"status":"ok","timestamp":1686588513459,"user":{"displayName":"Swapnil Gusani","userId":"03078760041423155735"},"user_tz":-330},"id":"5IJ3Uk31MZEx","outputId":"f3aa1502-76a4-43ce-f9e7-b2cb6afdd7d7"},"outputs":[],"source":["from utils import show_incorrect\n","show_incorrect() # Predicted vs Actual"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AluMosGgAKac"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1MoVBAbWmKAGtfQvvG8p53S7YohH6Xupk","timestamp":1686588546746},{"file_id":"1Q5nWvQHf96uMXt_o4z4YQwjSMcSHIPvz","timestamp":1686567383113},{"file_id":"1mQpZpPadx_wNIACXv7LLeTL7lnuIb6uW","timestamp":1686565166223},{"file_id":"https://github.com/swapniel99/erav1s7/blob/main/model_1.ipynb","timestamp":1686563366869},{"file_id":"1oVt7T6tb90Y1EXvFaIWgm72emqZZPXi4","timestamp":1684589382160}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
