{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Target:\n","\n","    1. Reach target accuracy of 99.4% with less than 20000 parameters and 20 epochs\n","\n","Result:\n","\n","    Best test accuracy: 99.49%\n","    Parameters: 18914\n","\n","Analysis:\n","\n","    1. 99.4% reaced at 11th epoch and stabilised later on"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2115,"status":"ok","timestamp":1686358368421,"user":{"displayName":"Abinesh Sankar","userId":"10831860094999218324"},"user_tz":240},"id":"N6cTPgyCkxmN","outputId":"9d0fa663-3814-46a2-b5f6-c7cd79db831e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","\n","!pip install torchsummary\n","from torchsummary import summary"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Select GPU or CPU in devices"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1686358368422,"user":{"displayName":"Abinesh Sankar","userId":"10831860094999218324"},"user_tz":240},"id":"Alxq4NG5k3Fy","outputId":"2c2253bc-ea15-47b9-9ca8-fa757b274060"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device Selected: cuda\n"]}],"source":["# Device\n","if torch.cuda.is_available():\n","    device = \"cuda\"\n","else:\n","    device = \"cpu\"\n","print(\"Device Selected:\", device)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Data Transformations\n","\n","We need to augment the data to better represent the trainig set and define what the model sees during training. \n","\n","Some of the transformations which come pre-built with PyTorch\n","\n","1. Resize\n","2. Scale\n","3. CenterCrop\n","4. Pad\n","5. Lambda\n","6. RandomApply"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Dataset and Creating Train/Test Split"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1113,"status":"ok","timestamp":1686358891465,"user":{"displayName":"Abinesh Sankar","userId":"10831860094999218324"},"user_tz":240},"id":"r_O04cbgk7sj","outputId":"1d2212da-20f3-4817-9821-e9c9c219d9d6"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["batch_size = 128\n","torch.manual_seed(1)\n","\n","kwargs = {'num_workers': 4, 'pin_memory': True} if device != 'cpu' else {}\n","\n","train_loader = torch.utils.data.DataLoader(\n","                datasets.MNIST('../data', train=True, download=True,\n","                               transform=transforms.Compose([\n","                                  transforms.RandomRotation((-8.0, 8.0), center=None, fill=None),\n","                                  transforms.ToTensor(),\n","                                  transforms.Normalize((0.1307,), (0.3081,))\n","                              ])),\n","                batch_size=batch_size, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","                datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                                transforms.ToTensor(),\n","                                transforms.Normalize((0.1307,), (0.3081,))\n","                              ])),\n","                batch_size=batch_size, shuffle=False, **kwargs)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Model definition"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686359492637,"user":{"displayName":"Abinesh Sankar","userId":"10831860094999218324"},"user_tz":240},"id":"x9f8OnSak7qf"},"outputs":[],"source":["class Net(nn.Module):\n","  def __init__(self):\n","    super(Net, self).__init__()\n","    self.conv1 = nn.Sequential(nn.Conv2d(1, 8, 3, padding=1, bias=False),       # In - 28x28x1, Out - 28x28x6, RF - 3x3\n","                                nn.ReLU(),\n","                                nn.BatchNorm2d(8),\n","                                nn.Conv2d(8, 16, 3, padding=1, bias=False),      # In - 28x28x6, Out - 28x28x12, RF - 5x5\n","                                nn.ReLU()\n","                              )\n","\n","    self.transition1 = nn.Sequential(nn.MaxPool2d(2, 2))                        # In - 28x28x12, Out - 14x14x12, RF - 6x6\n","\n","    self.conv2 = nn.Sequential(nn.Dropout(0.15),\n","                                nn.BatchNorm2d(16),\n","                                nn.Conv2d(16, 16, 3, padding=1, bias=False),     # In - 14x14x12, Out - 14x14x16, RF - 10x10\n","                                nn.ReLU(),\n","                                nn.BatchNorm2d(16),\n","                                nn.Conv2d(16, 32, 3, padding=1, bias=False),    # In - 14x14x16, Out - 14x14x16, RF - 14x14\n","                                nn.ReLU()\n","                              )\n","\n","    self.transition2 = nn.Sequential(nn.MaxPool2d(2, 2))                        # In - 14x14x16, Out - 7x7x16, RF - 16x16\n","\n","    self.conv3 = nn.Sequential(nn.Dropout(0.2),\n","                                nn.BatchNorm2d(32),\n","                                nn.Conv2d(32, 32, 3, padding=1, bias=False),    # In - 7x7x16, Out - 7x7x16, RF - 24x24\n","                                nn.ReLU()\n","                              )\n","\n","    self.final_layers = nn.Sequential(nn.AvgPool2d(7, 7),\n","                                      nn.BatchNorm2d(32),\n","                                      nn.Conv2d(32, 32, 1, bias=False),         # In - 7x7x16, Out - 7x7x32, RF - 32x32\n","                                      nn.ReLU(),\n","                                      nn.Conv2d(32, 10, 1),                     # In - 7x7x32, Out - 7x7x10, RF - 32x32\n","                                      nn.Flatten(),\n","                                      nn.LogSoftmax()\n","                                      )\n","\n","  def forward(self, x):\n","      x = self.conv1(x)\n","      x = self.transition1(x)\n","      x = self.conv2(x)\n","      x = self.transition2(x)\n","      x = self.conv3(x)\n","      x = self.final_layers(x)\n","      return x"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Model Summary"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1686359493591,"user":{"displayName":"Abinesh Sankar","userId":"10831860094999218324"},"user_tz":240},"id":"MbMqZAB4k7og","outputId":"9a3b538a-6d21-4c99-b0ce-826260a61950"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 8, 28, 28]              72\n","              ReLU-2            [-1, 8, 28, 28]               0\n","       BatchNorm2d-3            [-1, 8, 28, 28]              16\n","            Conv2d-4           [-1, 16, 28, 28]           1,152\n","              ReLU-5           [-1, 16, 28, 28]               0\n","         MaxPool2d-6           [-1, 16, 14, 14]               0\n","           Dropout-7           [-1, 16, 14, 14]               0\n","       BatchNorm2d-8           [-1, 16, 14, 14]              32\n","            Conv2d-9           [-1, 16, 14, 14]           2,304\n","             ReLU-10           [-1, 16, 14, 14]               0\n","      BatchNorm2d-11           [-1, 16, 14, 14]              32\n","           Conv2d-12           [-1, 32, 14, 14]           4,608\n","             ReLU-13           [-1, 32, 14, 14]               0\n","        MaxPool2d-14             [-1, 32, 7, 7]               0\n","          Dropout-15             [-1, 32, 7, 7]               0\n","      BatchNorm2d-16             [-1, 32, 7, 7]              64\n","           Conv2d-17             [-1, 32, 7, 7]           9,216\n","             ReLU-18             [-1, 32, 7, 7]               0\n","        AvgPool2d-19             [-1, 32, 1, 1]               0\n","      BatchNorm2d-20             [-1, 32, 1, 1]              64\n","           Conv2d-21             [-1, 32, 1, 1]           1,024\n","             ReLU-22             [-1, 32, 1, 1]               0\n","           Conv2d-23             [-1, 10, 1, 1]             330\n","          Flatten-24                   [-1, 10]               0\n","       LogSoftmax-25                   [-1, 10]               0\n","================================================================\n","Total params: 18,914\n","Trainable params: 18,914\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.64\n","Params size (MB): 0.07\n","Estimated Total Size (MB): 0.71\n","----------------------------------------------------------------\n"]}],"source":["model = Net().to(device)\n","summary(model, input_size=(1, 28, 28))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Train and test functions "]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":317,"status":"ok","timestamp":1686359502795,"user":{"displayName":"Abinesh Sankar","userId":"10831860094999218324"},"user_tz":240},"id":"IMbENwD2k7mQ"},"outputs":[],"source":["\n","from tqdm import tqdm\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    pbar = tqdm(train_loader)\n","    for batch_idx, (data, target) in enumerate(pbar):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        pbar.set_description(desc= f'Train set: Average loss={loss.item()} batch_id={batch_idx}')\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","\n","    return test_loss"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Defining optimizer + Training the model"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":495812,"status":"ok","timestamp":1686360000735,"user":{"displayName":"Abinesh Sankar","userId":"10831860094999218324"},"user_tz":240},"id":"SFdfAG-Lk7j0","outputId":"5d70a4a4-da68-4112-b680-b16e4fe107d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.11322592943906784 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 20.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0721, Accuracy: 9780/10000 (97.80%)\n","\n","Epoch 2: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.029797203838825226 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0446, Accuracy: 9860/10000 (98.60%)\n","\n","Epoch 3: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.013811890967190266 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 21.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0286, Accuracy: 9911/10000 (99.11%)\n","\n","Epoch 4: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.0526980459690094 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0273, Accuracy: 9915/10000 (99.15%)\n","\n","Epoch 5: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.10314694046974182 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 21.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0296, Accuracy: 9893/10000 (98.93%)\n","\n","Epoch 6: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.021662874147295952 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 21.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0268, Accuracy: 9909/10000 (99.09%)\n","\n","Epoch 7: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.031529683619737625 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 20.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0222, Accuracy: 9923/10000 (99.23%)\n","\n","Epoch 8: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.006742371246218681 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 21.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0234, Accuracy: 9921/10000 (99.21%)\n","\n","Epoch 9: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.018615566194057465 batch_id=468: 100%|██████████| 469/469 [00:23<00:00, 19.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0199, Accuracy: 9931/10000 (99.31%)\n","\n","Epoch 10: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.041133176535367966 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0188, Accuracy: 9939/10000 (99.39%)\n","\n","Epoch 11: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.08994594216346741 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0187, Accuracy: 9941/10000 (99.41%)\n","\n","Epoch 12: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.0420217327773571 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 22.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0176, Accuracy: 9945/10000 (99.45%)\n","\n","Epoch 13: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.0025235225912183523 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0181, Accuracy: 9938/10000 (99.38%)\n","\n","Epoch 14: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.05605626106262207 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 21.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0175, Accuracy: 9942/10000 (99.42%)\n","\n","Epoch 15: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.018690191209316254 batch_id=468: 100%|██████████| 469/469 [00:23<00:00, 19.73it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0188, Accuracy: 9932/10000 (99.32%)\n","\n","Epoch 16: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.0277359988540411 batch_id=468: 100%|██████████| 469/469 [00:22<00:00, 21.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0183, Accuracy: 9940/10000 (99.40%)\n","\n","Epoch 17: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.006007961463183165 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0164, Accuracy: 9945/10000 (99.45%)\n","\n","Epoch 18: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.028959505259990692 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.63it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0165, Accuracy: 9943/10000 (99.43%)\n","\n","Epoch 19: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.018927374854683876 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0154, Accuracy: 9949/10000 (99.49%)\n","\n","Epoch 20: \n"]},{"name":"stderr","output_type":"stream","text":["Train set: Average loss=0.002033132826909423 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.0175, Accuracy: 9940/10000 (99.40%)\n","\n"]}],"source":["model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.4, verbose=True)\n","\n","for epoch in range(0, 20):\n","    print(\"Epoch {}: \".format(epoch + 1))\n","    train(model, device, train_loader, optimizer, epoch)\n","    test_loss = test(model, device, test_loader)\n","    scheduler.step(test_loss)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Target validation accuracy of 99.4% reached in 11^th epoch"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOSvglNDpx/D4aTZablkl07","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
